"""
Predictor de Motivo de Rechazo - VERSI√ìN MEJORADA (Enero 2026)
===============================================================

MEJORAS IMPLEMENTADAS:
1. ‚úÖ Procesamiento de texto NLP del campo detalle_rechazo
2. ‚úÖ Features adicionales: marca, modelo, sucursal
3. ‚úÖ Manejo de clases desbalanceadas con class_weight
4. ‚úÖ Mejores hiperpar√°metros de RandomForest
5. ‚úÖ Motivos actualizados (11 categor√≠as reales)
6. ‚úÖ Features de piezas individuales
7. ‚úÖ Keywords optimizadas basadas en an√°lisis de textos reales (Enero 9, 2026)

KEYWORDS ACTUALIZADAS (Basadas en an√°lisis de 222 cotizaciones reales):
- Se analizaron todos los textos de detalle_rechazo en la BD
- Se reemplazaron keywords que NUNCA aparec√≠an con palabras reales
- Se agregaron t√©rminos frecuentes encontrados en los datos
- Mejora esperada en detecci√≥n: de 0-66% a 100% en varios motivos

PRECISION ESPERADA: 80%+ (mejora de ~42% vs versi√≥n anterior 37.78%)

EXPLICACI√ìN PARA PRINCIPIANTES:
Este modelo mejorado usa m√°s informaci√≥n para predecir el motivo de rechazo:
- Antes: Solo usaba costos y cantidad de piezas
- Ahora: Analiza tambi√©n el texto del rechazo, marca, modelo, y caracter√≠sticas de cada pieza
- Keywords: Palabras reales que los usuarios escriben, no palabras inventadas

Es como un detective que antes solo ve√≠a el precio, pero ahora tambi√©n lee
los comentarios del cliente y analiza el tipo de equipo.
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix
import logging
import joblib
import re

from .base import MLModelBase
from ..models import Cotizacion
from ..utils_cotizaciones import obtener_dataframe_cotizaciones

logger = logging.getLogger(__name__)


class PredictorMotivoRechazoMejorado(MLModelBase):
    """
    Predictor mejorado de motivos de rechazo con NLP y features avanzadas.
    
    MOTIVOS REALES DETECTADOS (11 categor√≠as):
    1. costo_alto - Cliente considera el precio muy elevado (21.6%)
    2. otro - Motivos no categorizados (22.1%)
    3. no_hay_partes - No hay piezas disponibles (12.2%)
    4. no_vale_pena - Costo cerca al valor del equipo (10.8%)
    5. no_especifica_motivo - Cliente no dio raz√≥n (10.8%)
    6. falta_de_respuesta - Cliente no contest√≥ (8.1%)
    7. solo_venta_mostrador - Opt√≥ por venta directa (5.0%)
    8. no_apto - Equipo no es reparable (3.6%)
    9. rechazo_sin_decision - Pendiente de decisi√≥n (2.7%)
    10. muchas_piezas - Demasiadas piezas necesarias (2.3%)
    11. tiempo_largo - Tiempo de reparaci√≥n muy largo (0.9%)
    """
    
    # Mapeo de motivos actualizado con los 11 reales
    MOTIVOS = {
        'costo_alto': {
            'nombre': 'Costo Muy Alto',
            'icono': 'üí∞',
            'descripcion': 'El cliente considera que el precio es excesivo',
            'keywords': ['costo', 'presupuesto', 'excedido', 'supera', 'm√°ximo', 'invertir', 'elevado', 'caro', 'precio', 'excede'],
            'acciones_sugeridas': [
                'Ofrecer descuento del 10-15% en mano de obra',
                'Proponer plan de pagos en 2 partes',
                'Eliminar piezas opcionales no cr√≠ticas'
            ]
        },
        'otro': {
            'nombre': 'Otro Motivo',
            'icono': '‚ùì',
            'descripcion': 'Motivo no especificado en categor√≠as est√°ndar',
            'keywords': ['otro', 'motivo', 'equipo', 'piezas', 'reparaci√≥n', 'acepta'],
            'acciones_sugeridas': [
                'Contactar al cliente para entender mejor',
                'Documentar el motivo espec√≠fico para futuras mejoras'
            ]
        },
        'no_hay_partes': {
            'nombre': 'No Hay Piezas Disponibles',
            'icono': 'üì¶',
            'descripcion': 'No hay partes en el mercado o proveedor',
            'keywords': ['disponible', 'mercado', 'piezas', 'no hay', 'stock', 'descontinuada', 'pieza', 'disponibles'],
            'acciones_sugeridas': [
                'Buscar piezas alternativas compatibles',
                'Ofrecer servicio de recuperaci√≥n de datos',
                'Proponer compra de equipo similar refurbished'
            ]
        },
        'no_vale_pena': {
            'nombre': 'No Vale la Pena Reparar',
            'icono': '‚öñÔ∏è',
            'descripcion': 'El costo de reparaci√≥n excede valor del equipo',
            'keywords': ['equipo nuevo', 'considera', 'viable', 'reparar', 'no vale', 'pena', 'valor'],
            'acciones_sugeridas': [
                'Ofrecer reparaci√≥n parcial (solo lo esencial)',
                'Proponer venta de piezas rescatables',
                'Descontar costo completo de mano de obra'
            ]
        },
        'no_especifica_motivo': {
            'nombre': 'Cliente No Especifica',
            'icono': 'ü§∑',
            'descripcion': 'Cliente no proporciona motivo espec√≠fico',
            'keywords': ['no especifica', 'sin motivo', 'no proporciona'],
            'acciones_sugeridas': [
                'Llamar para entender preocupaciones',
                'Ofrecer ajustes sin compromiso',
                'Enviar encuesta de satisfacci√≥n'
            ]
        },
        'falta_de_respuesta': {
            'nombre': 'Falta de Respuesta',
            'icono': 'üìµ',
            'descripcion': 'Cliente no respondi√≥ en tiempo l√≠mite',
            'keywords': ['no responde', 'respuesta', 'intentos', 'm√∫ltiples', 'despu√©s', 'falta'],
            'acciones_sugeridas': [
                'Enviar recordatorio por WhatsApp',
                'Extender plazo de vigencia',
                'Contactar por canal alternativo'
            ]
        },
        'solo_venta_mostrador': {
            'nombre': 'Solo Venta Mostrador',
            'icono': 'üõí',
            'descripcion': 'Cliente prefiere solo compra de productos',
            'keywords': ['venta', 'mostrador', 'solo', 'limpieza', 'mantenimiento', 'servicio'],
            'acciones_sugeridas': [
                'Procesar venta mostrador',
                'Ofrecer instalaci√≥n a precio reducido',
                'Sugerir kit completo de mejoras'
            ]
        },
        'no_apto': {
            'nombre': 'Equipo No Apto',
            'icono': 'üö´',
            'descripcion': 'Equipo no es candidato para reparaci√≥n',
            'keywords': ['apto', 'equipo', 'reparaci√≥n', 'diagnosticar', 'plaga', 'posible'],
            'acciones_sugeridas': [
                'Explicar por qu√© no es reparable',
                'Ofrecer recuperaci√≥n de datos',
                'Proponer reciclaje responsable'
            ]
        },
        'rechazo_sin_decision': {
            'nombre': 'Rechazo Sin Decisi√≥n',
            'icono': '‚è≥',
            'descripcion': 'Cliente quiere m√°s tiempo para decidir',
            'keywords': ['evaluar', 'evaluar√°', 'retira', 'opciones', 'consultar√°'],
            'acciones_sugeridas': [
                'Extender vigencia de cotizaci√≥n',
                'Ofrecer guardar equipo sin costo',
                'Programar seguimiento en 1 semana'
            ]
        },
        'muchas_piezas': {
            'nombre': 'Demasiadas Piezas',
            'icono': 'üîß',
            'descripcion': 'Reparaci√≥n requiere cambio de muchos componentes',
            'keywords': ['muchas', 'piezas', 'componentes', 'requiere', 'extensa', 'reparaci√≥n'],
            'acciones_sugeridas': [
                'Proponer reparaci√≥n por fases',
                'Priorizar solo piezas cr√≠ticas',
                'Ofrecer descuento por volumen'
            ]
        },
        'tiempo_largo': {
            'nombre': 'Tiempo de Reparaci√≥n Largo',
            'icono': '‚è∞',
            'descripcion': 'El tiempo estimado es muy extenso',
            'keywords': ['tiempo', 'espera', 'demora', 'inaceptable', 'tiempos', 'extenso'],
            'acciones_sugeridas': [
                'Priorizar pedido express de piezas',
                'Reasignar a t√©cnico con menor carga',
                'Ofrecer equipo de pr√©stamo'
            ]
        }
    }
    
    def __init__(self):
        """Inicializa el predictor mejorado."""
        super().__init__(model_name='motivos_predictor')  # Ahora usa nombre base (archivos ya fueron reemplazados)
        
        # Modelo con hiperpar√°metros optimizados
        self.model = RandomForestClassifier(
            n_estimators=200,        # M√°s √°rboles = mejor
            max_depth=15,            # Mayor profundidad
            min_samples_split=2,     # M√°s sensible
            min_samples_leaf=1,
            max_features='sqrt',     # Evita overfitting
            n_jobs=-1,
            random_state=42,
            class_weight='balanced_subsample'  # Manejo de desbalance
        )
        
        # Encoders
        self.label_encoder = LabelEncoder()
        self.feature_encoders = {
            'gama': LabelEncoder(),
            'tipo_equipo': LabelEncoder(),
            'sucursal': LabelEncoder(),
            'marca': LabelEncoder(),  # ‚úÖ NUEVO
        }
        
        # üÜï NUEVO: Vectorizador de texto para an√°lisis NLP
        # Stop words comunes en espa√±ol + palabras de contexto que no discriminan
        stop_words_spanish = [
            # Art√≠culos, pronombres, preposiciones
            'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
            'de', 'del', 'al', 'a', 'en', 'con', 'por', 'para',
            'que', 'es', 'y', 'o', 'si', 'no', 'se', 'su',
            'muy', 'm√°s', 'pero', 'como', 'sin', 'sobre',
            'est√°', 'est√°n', 'fue', 'fue', 'ser', 'ha', 'han',
            'tiene', 'tienen', 'esto', 'ese', 'esa', 'aqui',
            # Palabras de contexto espec√≠ficas del dominio (no discriminan motivos)
            'reparaci√≥n', 'reparacion', 'equipo', 'usuario', 'cliente',
            'cotizaci√≥n', 'cotizacion', 'rechaza', 'acepta', 'informa',
            'indica', 'menciona', 'confirma', 'notifica', 'dice',
            'desea', 'presenta', 'retira'
        ]
        
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=20,         # Top 20 palabras m√°s importantes
            ngram_range=(1, 2),      # Palabras individuales y pares
            stop_words=stop_words_spanish,  # Ignorar palabras comunes en espa√±ol
            min_df=2,                # Palabra debe aparecer en m√≠n 2 documentos
            lowercase=True,
            token_pattern=r'\b[a-z√°√©√≠√≥√∫√±]+\b'  # Solo palabras en espa√±ol
        )
        
        self.feature_names = []
        self.text_feature_names = []
        
        logger.info("‚úÖ PredictorMotivoRechazoMejorado inicializado")
    
    def preprocesar_texto(self, texto: str) -> str:
        """
        Limpia y normaliza el texto del detalle de rechazo.
        
        EXPLICACI√ìN PARA PRINCIPIANTES:
        Antes de analizar el texto, lo "limpiamos":
        - Convertimos a min√∫sculas
        - Eliminamos caracteres especiales
        - Normalizamos espacios
        
        Esto ayuda al modelo a reconocer patrones mejor.
        
        Args:
            texto: Texto crudo del detalle de rechazo
        
        Returns:
            str: Texto limpio y normalizado
        """
        if not texto or pd.isna(texto):
            return ""
        
        # Convertir a string y min√∫sculas
        texto = str(texto).lower()
        
        # Eliminar URLs
        texto = re.sub(r'http\S+|www\S+', '', texto)
        
        # Eliminar emails
        texto = re.sub(r'\S+@\S+', '', texto)
        
        # Mantener solo letras, n√∫meros y espacios
        texto = re.sub(r'[^a-z√°√©√≠√≥√∫√±0-9\s]', ' ', texto)
        
        # Normalizar espacios
        texto = re.sub(r'\s+', ' ', texto).strip()
        
        return texto
    
    def preparar_features(self, df: pd.DataFrame, entrenar_tfidf: bool = False) -> pd.DataFrame:
        """
        Prepara features mejoradas incluyendo an√°lisis de texto NLP.
        
        MEJORAS vs versi√≥n anterior:
        1. ‚úÖ Features de piezas individuales
        2. ‚úÖ An√°lisis NLP del detalle_rechazo
        3. ‚úÖ Marca y modelo del equipo
        4. ‚úÖ Sucursal origen
        5. ‚úÖ Features derivadas adicionales
        
        Args:
            df: DataFrame con cotizaciones
            entrenar_tfidf: Si True, entrena el vectorizador TF-IDF
        
        Returns:
            DataFrame con features preparadas
        """
        df_features = df.copy()
        
        # =========================================
        # FEATURES NUM√âRICAS B√ÅSICAS
        # =========================================
        numeric_features = [
            'costo_total',
            'costo_mano_obra',
            'costo_total_piezas',
            'total_piezas',
            'piezas_necesarias',
            'piezas_sugeridas_tecnico',
        ]
        
        # =========================================
        # FEATURES DERIVADAS MEJORADAS
        # =========================================
        
        # Ratios y porcentajes
        costo_promedio = df_features['costo_total'].median()
        df_features['ratio_vs_promedio'] = (
            df_features['costo_total'] / costo_promedio
        ).fillna(1.0)
        
        df_features['porcentaje_mano_obra'] = (
            df_features['costo_mano_obra'] / df_features['costo_total'] * 100
        ).fillna(0)
        
        df_features['costo_por_pieza'] = (
            df_features['costo_total_piezas'] / df_features['total_piezas']
        ).fillna(0)
        
        df_features['porcentaje_necesarias'] = (
            df_features['piezas_necesarias'] / df_features['total_piezas'] * 100
        ).fillna(0)
        
        # üÜï NUEVO: Ratio piezas sugeridas vs necesarias
        df_features['ratio_sugeridas_necesarias'] = (
            df_features['piezas_sugeridas_tecnico'] / 
            (df_features['piezas_necesarias'] + 1)  # +1 para evitar divisi√≥n por 0
        ).fillna(0)
        
        # Binarios
        df_features['tiene_descuento'] = df_features['descontar_mano_obra'].astype(int)
        
        # Tiempo de respuesta
        if 'dias_hasta_respuesta' in df_features.columns:
            df_features['tiempo_respuesta'] = df_features['dias_hasta_respuesta'].fillna(
                df_features['dias_hasta_respuesta'].median()
            )
        else:
            df_features['tiempo_respuesta'] = 0
        
        # Rangos de costo (mejorados)
        df_features['rango_muy_bajo'] = (df_features['costo_total'] < 3000).astype(int)
        df_features['rango_bajo'] = (
            (df_features['costo_total'] >= 3000) & 
            (df_features['costo_total'] < 5000)
        ).astype(int)
        df_features['rango_medio'] = (
            (df_features['costo_total'] >= 5000) & 
            (df_features['costo_total'] < 8000)
        ).astype(int)
        df_features['rango_alto'] = (
            (df_features['costo_total'] >= 8000) & 
            (df_features['costo_total'] < 12000)
        ).astype(int)
        df_features['rango_muy_alto'] = (df_features['costo_total'] >= 12000).astype(int)
        
        # Cantidad de piezas (mejorado)
        df_features['muy_pocas_piezas'] = (df_features['total_piezas'] == 1).astype(int)
        df_features['pocas_piezas'] = (df_features['total_piezas'] == 2).astype(int)
        df_features['piezas_moderadas'] = (
            (df_features['total_piezas'] >= 3) & 
            (df_features['total_piezas'] <= 5)
        ).astype(int)
        df_features['muchas_piezas'] = (df_features['total_piezas'] > 5).astype(int)
        
        # Temporales
        if 'fecha_envio' in df_features.columns:
            df_features['dia_semana'] = pd.to_datetime(df_features['fecha_envio']).dt.dayofweek
            df_features['mes'] = pd.to_datetime(df_features['fecha_envio']).dt.month
            df_features['es_fin_semana'] = (df_features['dia_semana'] >= 5).astype(int)
        else:
            df_features['dia_semana'] = 0
            df_features['mes'] = 1
            df_features['es_fin_semana'] = 0
        
        # =========================================
        # üÜï FEATURES DE TEXTO NLP
        # =========================================
        if 'detalle_rechazo' in df_features.columns and not df_features['detalle_rechazo'].isna().all():
            # Preprocesar texto
            textos_limpios = df_features['detalle_rechazo'].fillna('').apply(self.preprocesar_texto)
            
            # Entrenar o transformar con TF-IDF
            if entrenar_tfidf:
                # Entrenar vectorizador con el corpus completo
                tfidf_matrix = self.tfidf_vectorizer.fit_transform(textos_limpios)
                self.text_feature_names = [
                    f'texto_{name}' 
                    for name in self.tfidf_vectorizer.get_feature_names_out()
                ]
            else:
                # Transformar usando vectorizador ya entrenado
                try:
                    tfidf_matrix = self.tfidf_vectorizer.transform(textos_limpios)
                except:
                    # Si falla, usar vectores vac√≠os
                    tfidf_matrix = np.zeros((len(textos_limpios), len(self.text_feature_names)))
            
            # Convertir matriz TF-IDF a DataFrame
            df_texto = pd.DataFrame(
                tfidf_matrix.toarray(),
                columns=self.text_feature_names,
                index=df_features.index
            )
            
            # Agregar features de texto al DataFrame principal
            df_features = pd.concat([df_features, df_texto], axis=1)
            
            # Features adicionales del texto
            df_features['longitud_detalle'] = textos_limpios.str.len()
            df_features['tiene_detalle'] = (df_features['longitud_detalle'] > 10).astype(int)
        else:
            # üÜï CASO PREDICCI√ìN: No hay detalle_rechazo disponible
            # Crear features de texto vac√≠as (todas en 0)
            if hasattr(self, 'text_feature_names') and self.text_feature_names:
                # Usar nombres de features del entrenamiento
                for text_feature in self.text_feature_names:
                    df_features[text_feature] = 0.0
            df_features['longitud_detalle'] = 0
            df_features['tiene_detalle'] = 0
        
        # =========================================
        # FEATURES CATEG√ìRICAS (codificar)
        # =========================================
        for col, encoder in self.feature_encoders.items():
            if col in df_features.columns:
                valores = df_features[col].fillna('desconocido').astype(str).str.lower().str.strip()
                
                # Entrenar encoder si no est√° entrenado
                if not hasattr(encoder, 'classes_'):
                    encoder.fit(valores)
                
                # Manejar valores no vistos
                clases_conocidas = set(encoder.classes_)
                valor_por_defecto = encoder.classes_[0]
                
                valores_safe = valores.copy()
                mascara_desconocidos = ~valores.isin(clases_conocidas)
                
                if mascara_desconocidos.any():
                    valores_safe[mascara_desconocidos] = valor_por_defecto
                
                df_features[f'{col}_encoded'] = encoder.transform(valores_safe)
            else:
                # üÜï CASO PREDICCI√ìN: La columna no existe
                # Usar valor por defecto (primera clase conocida)
                if hasattr(encoder, 'classes_') and len(encoder.classes_) > 0:
                    # Transformar el valor por defecto
                    valor_default = encoder.classes_[0]
                    # Crear array con el valor por defecto repetido
                    valores_default = pd.Series([valor_default] * len(df_features))
                    df_features[f'{col}_encoded'] = encoder.transform(valores_default)
                else:
                    # Si no hay clases entrenadas, usar 0
                    df_features[f'{col}_encoded'] = 0
        
        # =========================================
        # SELECCIONAR FEATURES FINALES
        # =========================================
        final_features = [
            # Num√©ricas originales
            'costo_total',
            'costo_mano_obra',
            'costo_total_piezas',
            'total_piezas',
            'piezas_necesarias',
            'piezas_sugeridas_tecnico',
            
            # Derivadas
            'ratio_vs_promedio',
            'porcentaje_mano_obra',
            'costo_por_pieza',
            'porcentaje_necesarias',
            'ratio_sugeridas_necesarias',  # NUEVO
            'tiene_descuento',
            'tiempo_respuesta',
            
            # Rangos de costo
            'rango_muy_bajo',
            'rango_bajo',
            'rango_medio',
            'rango_alto',
            'rango_muy_alto',
            
            # Rangos de piezas
            'muy_pocas_piezas',
            'pocas_piezas',
            'piezas_moderadas',
            'muchas_piezas',
            
            # Temporales
            'dia_semana',
            'mes',
            'es_fin_semana',
            
            # Texto
            'longitud_detalle',
            'tiene_detalle',
            
            # Categ√≥ricas codificadas
            'gama_encoded',
            'tipo_equipo_encoded',
            'sucursal_encoded',  # NUEVO (si existe)
            'marca_encoded',     # NUEVO (si existe)
        ]
        
        # Agregar features de texto TF-IDF
        final_features.extend(self.text_feature_names)
        
        # Filtrar solo features que existan
        final_features = [f for f in final_features if f in df_features.columns]
        
        # Guardar nombres de features
        self.feature_names = final_features
        
        # Rellenar NaN y limpiar infinitos
        df_features[final_features] = df_features[final_features].fillna(0)
        df_features[final_features] = df_features[final_features].replace(
            [np.inf, -np.inf], 0
        )
        
        return df_features[final_features]
    
    def entrenar(
        self, 
        fecha_inicio: Optional[str] = None,
        fecha_fin: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Entrena el modelo mejorado con an√°lisis NLP y features avanzadas.
        
        MEJORAS vs versi√≥n anterior:
        - Procesa el texto del detalle_rechazo con TF-IDF
        - Usa m√°s features (40+ vs 21 anterior)
        - Mejor manejo de clases desbalanceadas
        - Hiperpar√°metros optimizados
        
        Args:
            fecha_inicio: Fecha inicio para filtrar datos
            fecha_fin: Fecha fin para filtrar datos
        
        Returns:
            dict: M√©tricas de evaluaci√≥n del modelo
        """
        logger.info("üìä Obteniendo datos de cotizaciones rechazadas...")
        
        # Obtener datos completos
        df = obtener_dataframe_cotizaciones(
            fecha_inicio=fecha_inicio,
            fecha_fin=fecha_fin
        )
        
        # Filtrar SOLO cotizaciones rechazadas CON motivo especificado
        df_rechazadas = df[
            (df['aceptada'] == False) & 
            (df['motivo_rechazo'].notna()) &
            (df['motivo_rechazo'] != '')
        ].copy()
        
        if len(df_rechazadas) < 20:
            raise ValueError(
                f"‚ùå Datos insuficientes para entrenar. Se necesitan m√≠nimo 20 "
                f"cotizaciones rechazadas con motivo, pero solo hay {len(df_rechazadas)}."
            )
        
        logger.info(
            f"‚úÖ {len(df_rechazadas)} cotizaciones rechazadas con motivo encontradas"
        )
        
        # Validar datos
        self.validar_datos(df_rechazadas, min_samples=20)
        
        # Preparar features (X) - ENTRENAR TF-IDF
        logger.info("üîß Preparando features mejoradas con NLP...")
        X = self.preparar_features(df_rechazadas, entrenar_tfidf=True)
        
        # Preparar target (y) - motivo de rechazo
        y = df_rechazadas['motivo_rechazo'].values
        
        # Entrenar label encoder
        self.label_encoder.fit(y)
        y_encoded = self.label_encoder.transform(y)
        
        logger.info(f"‚úÖ {len(self.feature_names)} features preparadas")
        logger.info(f"   ({len(self.text_feature_names)} features de texto NLP)")
        logger.info(f"   Motivos √∫nicos detectados: {list(self.label_encoder.classes_)}")
        
        # ========================================
        # VERIFICAR CLASES CON POCOS EJEMPLOS
        # ========================================
        # EXPLICACI√ìN PARA PRINCIPIANTES:
        # Si una categor√≠a tiene solo 1 ejemplo, no se puede usar stratify
        # porque necesita al menos 2 ejemplos (1 para train, 1 para test).
        # Soluci√≥n: Filtrar categor√≠as con <2 ejemplos o desactivar stratify.
        
        from collections import Counter
        distribucion_clases = Counter(y_encoded)
        clases_problematicas = {k: v for k, v in distribucion_clases.items() if v < 2}
        
        if clases_problematicas:
            # Hay clases con <2 ejemplos
            motivos_problematicos = [
                self.label_encoder.classes_[clase_id] 
                for clase_id in clases_problematicas.keys()
            ]
            logger.warning(
                f"‚ö†Ô∏è Clases con <2 ejemplos detectadas: {motivos_problematicos}"
            )
            logger.warning(
                f"   Distribuci√≥n: {dict(zip(motivos_problematicos, clases_problematicas.values()))}"
            )
            logger.warning(
                f"   Desactivando stratify para evitar error..."
            )
            
            # Opci√≥n 1: Filtrar clases con <5 ejemplos (recomendado para ML)
            # Crear m√°scara para mantener solo clases con >=5 ejemplos
            mask_validas = np.isin(y_encoded, [
                clase_id for clase_id, count in distribucion_clases.items() 
                if count >= 5
            ])
            
            if mask_validas.sum() >= 20:  # Si quedan suficientes datos
                logger.info(
                    f"üîß Filtrando clases con <5 ejemplos para mejor entrenamiento..."
                )
                X_filtrado = X[mask_validas]
                y_filtrado = y_encoded[mask_validas]
                y_original_filtrado = y[mask_validas]
                
                # Re-entrenar label encoder con clases filtradas
                self.label_encoder.fit(y_original_filtrado)
                y_filtrado_encoded = self.label_encoder.transform(y_original_filtrado)
                
                logger.info(
                    f"‚úÖ Dataset filtrado: {len(X_filtrado)} muestras, "
                    f"{len(self.label_encoder.classes_)} motivos"
                )
                
                # Dividir con stratify (ahora todas las clases tienen >=5 ejemplos)
                X_train, X_test, y_train, y_test = train_test_split(
                    X_filtrado, y_filtrado_encoded,
                    test_size=0.2,
                    random_state=42,
                    stratify=y_filtrado_encoded
                )
            else:
                # No hay suficientes datos despu√©s de filtrar
                logger.warning(
                    f"‚ö†Ô∏è No hay suficientes datos despu√©s de filtrar. "
                    f"Usando todos los datos SIN stratify..."
                )
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y_encoded,
                    test_size=0.2,
                    random_state=42,
                    stratify=None  # Sin estratificaci√≥n
                )
        else:
            # Todo bien, todas las clases tienen >=2 ejemplos
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_encoded,
                test_size=0.2,
                random_state=42,
                stratify=y_encoded
            )
        
        logger.info(f"üìà Entrenando modelo MEJORADO con {len(X_train)} muestras...")
        
        # ENTRENAR MODELO
        self.model.fit(X_train, y_train)
        
        logger.info("‚úÖ Modelo entrenado exitosamente!")
        
        # Hacer predicciones en test set
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.predict_proba(X_test)
        
        # Calcular m√©tricas
        metricas = self.calcular_metricas_clasificacion(y_test, y_pred, y_pred_proba)
        
        # Agregar informaci√≥n adicional de entrenamiento
        metricas['muestras_entrenamiento'] = len(X_train)
        metricas['muestras_prueba'] = len(X_test)
        metricas['total_muestras'] = len(df_rechazadas)
        
        # Distribuci√≥n de motivos
        distribucion_motivos = pd.Series(y).value_counts().to_dict()
        metricas['distribucion_motivos'] = distribucion_motivos
        
        # Feature importance (Top 15)
        feature_importance = pd.DataFrame({
            'feature': self.feature_names,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        metricas['feature_importance'] = feature_importance.head(15).to_dict('records')
        metricas['motivos_detectados'] = list(self.label_encoder.classes_)
        
        # üÜï NUEVO: Reporte de clasificaci√≥n detallado
        # Usar labels expl√≠citos para evitar error cuando una clase no aparece en test
        target_names = [str(name) for name in self.label_encoder.classes_]
        labels = list(range(len(target_names)))  # [0, 1, 2, ..., 10]
        
        reporte = classification_report(
            y_test, 
            y_pred,
            labels=labels,  # üîß CORREGIDO: Especificar labels expl√≠citos
            target_names=target_names,
            output_dict=True,
            zero_division=0
        )
        metricas['reporte_clasificacion'] = reporte
        
        # Actualizar metadata
        self.metadata.update({
            'total_samples': len(df_rechazadas),
            'muestras_entrenamiento': len(X_train),
            'muestras_prueba': len(X_test),
            'features': self.feature_names,
            'text_features': self.text_feature_names,
            'motivos': list(self.label_encoder.classes_),
            'metrics': metricas,
            'last_trained': pd.Timestamp.now().isoformat(),
            'version': 'v2_mejorado'
        })
        
        self.is_trained = True
        
        # Imprimir resumen MEJORADO
        print("\n" + "="*80)
        print("üìä M√âTRICAS DEL PREDICTOR DE MOTIVOS - VERSI√ìN MEJORADA")
        print("="*80)
        print(f"Accuracy (Precisi√≥n General): {metricas['accuracy']:.2%}")
        print(f"Precision (Weighted): {metricas['precision']:.2%}")
        print(f"Recall (Weighted): {metricas['recall']:.2%}")
        print(f"F1-Score (Weighted): {metricas['f1_score']:.2%}")
        
        print(f"\nüéØ Motivos Detectados: {len(self.label_encoder.classes_)}")
        for motivo in self.label_encoder.classes_:
            count = distribucion_motivos.get(motivo, 0)
            pct = (count / len(df_rechazadas)) * 100
            print(f"   - {motivo:30s} | {count:4d} casos ({pct:5.1f}%)")
        
        print("\nüîù Top 10 Features M√°s Importantes:")
        for i, row in enumerate(feature_importance.head(10).itertuples(), 1):
            feature_type = "üìù Texto" if row.feature in self.text_feature_names else "üìä Num√©rica"
            print(f"   {i:2d}. {feature_type} | {row.feature:35s} | {row.importance:.4f}")
        
        print("\nüìà Rendimiento por Motivo (Top 5):")
        for motivo, metricas_motivo in list(reporte.items())[:5]:
            if isinstance(metricas_motivo, dict) and 'f1-score' in metricas_motivo:
                f1 = metricas_motivo['f1-score']
                support = metricas_motivo['support']
                print(f"   - {motivo:30s} | F1: {f1:.2%} | Muestras: {support}")
        
        print("="*80)
        
        # Guardar modelo (incluyendo vectorizador TF-IDF)
        self.guardar_modelo()
        
        return metricas
    
    def guardar_modelo(self) -> None:
        """Guarda el modelo incluyendo encoders y vectorizador TF-IDF."""
        # Llamar al m√©todo padre
        super().guardar_modelo()
        
        # Guardar encoders y vectorizador
        encoders_path = self.model_dir / f'{self.model_name}_encoders.pkl'
        encoders_data = {
            'label_encoder': self.label_encoder,
            'feature_encoders': self.feature_encoders,
            'tfidf_vectorizer': self.tfidf_vectorizer,  # üÜï NUEVO
            'text_feature_names': self.text_feature_names  # üÜï NUEVO
        }
        joblib.dump(encoders_data, encoders_path)
        logger.info(f"üíæ Encoders y TF-IDF guardados en: {encoders_path}")
    
    def cargar_modelo(self) -> bool:
        """Carga el modelo incluyendo encoders y vectorizador TF-IDF."""
        # Llamar al m√©todo padre
        resultado = super().cargar_modelo()
        
        # Cargar encoders y vectorizador
        encoders_path = self.model_dir / f'{self.model_name}_encoders.pkl'
        if encoders_path.exists():
            encoders_data = joblib.load(encoders_path)
            self.label_encoder = encoders_data['label_encoder']
            self.feature_encoders = encoders_data['feature_encoders']
            self.tfidf_vectorizer = encoders_data.get('tfidf_vectorizer')
            self.text_feature_names = encoders_data.get('text_feature_names', [])
            logger.info(f"‚úÖ Encoders y TF-IDF cargados desde: {encoders_path}")
        else:
            logger.warning(f"‚ö†Ô∏è No se encontraron encoders en: {encoders_path}")
        
        return resultado
    
    def predecir_motivo(
        self, 
        cotizacion_features: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Predice el motivo probable de rechazo (VERSI√ìN MEJORADA).
        
        MEJORAS vs versi√≥n anterior:
        - Analiza el texto del detalle_rechazo
        - Usa features avanzadas (marca, modelo, etc.)
        - Mayor precisi√≥n en las predicciones
        
        Args:
            cotizacion_features: Diccionario con caracter√≠sticas de la cotizaci√≥n
                DEBE incluir 'detalle_rechazo' para an√°lisis NLP
        
        Returns:
            dict: Resultado de la predicci√≥n mejorada
        """
        if not self.is_trained:
            try:
                self.cargar_modelo()
            except FileNotFoundError:
                raise ValueError(
                    "Modelo no entrenado. Ejecuta entrenar() primero."
                )
        
        # Convertir dict a DataFrame
        df_input = pd.DataFrame([cotizacion_features])
        
        # Preparar features (sin entrenar TF-IDF)
        X = self.preparar_features(df_input, entrenar_tfidf=False)
        
        # Predecir probabilidades
        proba = self.model.predict_proba(X)[0]
        
        # Obtener √≠ndice del motivo con mayor probabilidad
        idx_principal = np.argmax(proba)
        motivo_principal = self.label_encoder.classes_[idx_principal]
        prob_principal = proba[idx_principal]
        
        # Determinar confianza
        if prob_principal >= 0.7:
            confianza = 'alta'
            confianza_icono = 'üü¢'
        elif prob_principal >= 0.5:
            confianza = 'media'
            confianza_icono = 'üü°'
        else:
            confianza = 'baja'
            confianza_icono = 'üî¥'
        
        # Obtener informaci√≥n del motivo
        motivo_info = self.MOTIVOS.get(motivo_principal, {
            'nombre': motivo_principal.replace('_', ' ').title(),
            'icono': '‚ùì',
            'descripcion': 'Motivo no catalogado',
            'acciones_sugeridas': []
        })
        
        # Motivos alternativos (top 3 excluyendo el principal)
        motivos_alternativos = []
        for idx, prob in enumerate(proba):
            if idx != idx_principal and prob > 0.05:
                motivo = self.label_encoder.classes_[idx]
                motivo_alt_info = self.MOTIVOS.get(motivo, {})
                
                motivos_alternativos.append({
                    'motivo': motivo,
                    'nombre': motivo_alt_info.get('nombre', motivo),
                    'probabilidad': float(prob),
                    'probabilidad_pct': f"{prob*100:.1f}%",
                    'icono': motivo_alt_info.get('icono', '‚ùì')
                })
        
        # Ordenar por probabilidad descendente y tomar top 3
        motivos_alternativos = sorted(
            motivos_alternativos,
            key=lambda x: x['probabilidad'],
            reverse=True
        )[:3]
        
        # Resultado completo
        resultado = {
            'motivo_principal': motivo_principal,
            'motivo_nombre': motivo_info['nombre'],
            'motivo_icono': motivo_info['icono'],
            'motivo_descripcion': motivo_info['descripcion'],
            'probabilidad': float(prob_principal),
            'probabilidad_pct': f"{prob_principal*100:.1f}%",
            'confianza': confianza,
            'confianza_icono': confianza_icono,
            'motivos_alternativos': motivos_alternativos,
            'acciones_sugeridas': motivo_info['acciones_sugeridas'],
            'todas_probabilidades': {
                self.label_encoder.classes_[i]: float(p) 
                for i, p in enumerate(proba)
            },
            'version': 'v2_mejorado'
        }
        
        return resultado
